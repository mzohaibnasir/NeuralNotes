{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOtQuYxtnJiRfqffFcyfzzu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mzohaibnasir/NeuralNotes/blob/main/03_deepDiveIntoBasics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Minibatch Training"
      ],
      "metadata": {
        "id": "TvS7nn4_nePl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle,gzip,math,os,time,shutil,torch,matplotlib as mpl,numpy as np,matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "from torch import tensor,nn\n",
        "import torch.nn.functional as F\n",
        "from fastcore.test import test_close\n"
      ],
      "metadata": {
        "id": "gc0rwmBVnh2w"
      },
      "execution_count": 510,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MNIST_URL='https://github.com/mnielsen/neural-networks-and-deep-learning/blob/d15df08a69ed33ae16a2fff874f83b57a956172c/data/mnist.pkl.gz?raw=true'\n",
        "path_data = Path('data')\n",
        "path_data.mkdir(exist_ok=True )\n",
        "path_gz=path_data/'mnist.pkl.gz'\n",
        "path_gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dWUrQuMfniy3",
        "outputId": "881a1f2e-36f8-4f25-bb71-0760c89c9e69"
      },
      "execution_count": 511,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Path('data/mnist.pkl.gz')"
            ]
          },
          "metadata": {},
          "execution_count": 511
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from urllib.request import urlretrieve\n",
        "\n",
        "if not path_gz.exists(): urlretrieve(MNIST_URL, path_gz)"
      ],
      "metadata": {
        "id": "8Tg9Z2NKni06"
      },
      "execution_count": 512,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "\n",
        "mpl.rcParams['image.cmap'] = 'gray'\n",
        "torch.set_printoptions(precision=2, linewidth=125, sci_mode=False)\n",
        "np.set_printoptions(precision=2, linewidth=125)\n"
      ],
      "metadata": {
        "id": "y-R1O60Cni3P"
      },
      "execution_count": 513,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQ17fE1hni48",
        "outputId": "a9c8e1bf-c0fb-4c25-d2d8-de436bc3f97c"
      },
      "execution_count": 514,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 16656\n",
            "-rw-r--r-- 1 root root 17051982 Jan 24 14:40 mnist.pkl.gz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with gzip.open(path_gz, 'rb') as f:   #read as binary as opposed to text\n",
        "   ((x_train,y_train), (x_valid,y_valid), _) = pickle.load(f, encoding='latin-1') #destructuring\n",
        "x_train, y_train, x_valid, y_valid = map(tensor, [x_train, y_train, x_valid, y_valid])"
      ],
      "metadata": {
        "id": "L5cfYFRwni6m"
      },
      "execution_count": 515,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W_TY16NRni8g"
      },
      "execution_count": 515,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n,m = x_train.shape\n",
        "c = y_train.max()+1\n",
        "nh = 50\n"
      ],
      "metadata": {
        "id": "-4wkKeZ7ni-G"
      },
      "execution_count": 516,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, n_in, nh, n_out):\n",
        "        super().__init__()\n",
        "        self.layers = [nn.Linear(n_in,nh), nn.ReLU(), nn.Linear(nh,n_out)]\n",
        "\n",
        "    def __call__(self, x):\n",
        "        for l in self.layers: x = l(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "ATdy9A7kni_1"
      },
      "execution_count": 517,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model(m, nh, 10)\n",
        "pred = model(x_train)\n",
        "pred.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4e2xfiynjCG",
        "outputId": "3b30233e-c293-4f76-e588-d99fdbc9b6f1"
      },
      "execution_count": 518,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([50000, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 518
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### CE loss"
      ],
      "metadata": {
        "id": "jyJTU38InjEc"
      },
      "execution_count": 519,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def log_softmax(x):\n",
        "  print(x.shape)\n",
        "  return (x.exp()/x.exp().sum(-1, keepdim=True)).shape\n",
        "log_softmax(pred)"
      ],
      "metadata": {
        "id": "8-nY1xrTnjG8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b2ab772-0322-4344-bfbe-4837488ad9a2"
      },
      "execution_count": 520,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([50000, 10])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([50000, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 520
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def log_softmax(x):\n",
        "  # print(x.shape)\n",
        "  return (x.exp()/x.exp().sum(-1, keepdim=True)).log()\n",
        "log_softmax(pred)"
      ],
      "metadata": {
        "id": "nTI-2__pnjI9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d512a4e9-bffe-494b-a3fb-81992e43eaa4"
      },
      "execution_count": 521,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-2.36, -2.28, -2.09,  ..., -2.43, -2.47, -2.11],\n",
              "        [-2.37, -2.25, -2.09,  ..., -2.46, -2.43, -2.11],\n",
              "        [-2.34, -2.31, -2.14,  ..., -2.44, -2.48, -2.14],\n",
              "        ...,\n",
              "        [-2.26, -2.25, -2.13,  ..., -2.36, -2.53, -2.17],\n",
              "        [-2.39, -2.30, -2.18,  ..., -2.38, -2.42, -2.11],\n",
              "        [-2.40, -2.25, -2.14,  ..., -2.38, -2.45, -2.23]], grad_fn=<LogBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 521
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred.exp().shape , pred.exp().sum(-1)[:,None].shape"
      ],
      "metadata": {
        "id": "uEU_eMgOnjLT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "889a16b2-f744-4561-f29a-cf1b63b6d2bb"
      },
      "execution_count": 522,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([50000, 10]), torch.Size([50000, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 522
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred.shape"
      ],
      "metadata": {
        "id": "h1sobHmEnjNV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08e4cefc-34f1-4e98-fc47-9d4ecb8a64f8"
      },
      "execution_count": 523,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([50000, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 523
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "we'll try to use log rules to simply softmax funcction\n",
        "\n",
        "`e^x and log x are opposite`"
      ],
      "metadata": {
        "id": "TLbz6V4BgpkD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def log_softmax(x):\n",
        "  return x - x.exp().sum(-1, keepdim=True).log()"
      ],
      "metadata": {
        "id": "saKpYskknjPN"
      },
      "execution_count": 524,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def logsumexp(x):\n",
        "  m = x.max(-1)[0]  # max value of `x`\n",
        "  return m + (x-m[:,None]).exp().sum(-1).log()  #logsumexp trick"
      ],
      "metadata": {
        "id": "sAK7z424njRn"
      },
      "execution_count": 525,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# in pytorch\n",
        "\n",
        "def log_softmax(x):\n",
        "  return x - x.logsumexp(-1, keepdim=True)"
      ],
      "metadata": {
        "id": "1WeVG0MNnjUq"
      },
      "execution_count": 526,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_close( logsumexp(pred), pred.logsumexp(-1))\n",
        "sm_pred = log_softmax(pred)\n",
        "sm_pred"
      ],
      "metadata": {
        "id": "W_I2zjpAnjXQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "115e28b0-e7c1-4379-8c58-48a6b53dcdec"
      },
      "execution_count": 527,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-2.36, -2.28, -2.09,  ..., -2.43, -2.47, -2.11],\n",
              "        [-2.37, -2.25, -2.09,  ..., -2.46, -2.43, -2.11],\n",
              "        [-2.34, -2.31, -2.14,  ..., -2.44, -2.48, -2.14],\n",
              "        ...,\n",
              "        [-2.26, -2.25, -2.13,  ..., -2.36, -2.53, -2.17],\n",
              "        [-2.39, -2.30, -2.18,  ..., -2.38, -2.42, -2.11],\n",
              "        [-2.40, -2.25, -2.14,  ..., -2.38, -2.45, -2.23]], grad_fn=<SubBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 527
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The cross entropy loss for some target\n",
        " and some prediction  p(x) is given by:\n",
        "      - sum( x . log(p(x)))\n",
        "\n",
        "  But since our xs are 1-hot encoded (actually, they're just the integer indices), this can be rewritten as -log(pi) where i is the index of the desired target.\n",
        "\n",
        "This can be done using numpy-style integer array indexing. Note that PyTorch supports all the tricks in the advanced indexing methods discussed in that link."
      ],
      "metadata": {
        "id": "fET2pqYnkHwJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train[:3]  # actual values of y_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTBjjbCMjSDe",
        "outputId": "8681dbb6-4fe8-4362-bc49-7a0a7d3932fd"
      },
      "execution_count": 528,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([5, 0, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 528
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# now in our softmaax prediction `sm_pred`, we want to get 5th prediction of 0, 0th of 1, and 4th of 2\n",
        "\n",
        "sm_pred[0,5], sm_pred[1,0], sm_pred[2,4]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6d78JWNjSF4",
        "outputId": "493d91fe-0aae-4a77-82f2-e24c2a58bded"
      },
      "execution_count": 529,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(-2.40, grad_fn=<SelectBackward0>),\n",
              " tensor(-2.37, grad_fn=<SelectBackward0>),\n",
              " tensor(-2.14, grad_fn=<SelectBackward0>))"
            ]
          },
          "metadata": {},
          "execution_count": 529
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sm_pred.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y1wUYT5DD7_l",
        "outputId": "c85f41ad-539c-4350-caca-879c7b0c3238"
      },
      "execution_count": 530,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([50000, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 530
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sm_pred[[0,1,2], y_train[:3]]     # [rows, cols]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LfE6014YjSHY",
        "outputId": "50b465a6-fba9-4292-f73b-40f348bae2a4"
      },
      "execution_count": 531,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-2.40, -2.37, -2.14], grad_fn=<IndexBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 531
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sm_pred[range(y_train.shape[0])]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XlalSCABC8sq",
        "outputId": "b57d7201-03ea-4766-a295-bccc0032a680"
      },
      "execution_count": 532,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-2.36, -2.28, -2.09,  ..., -2.43, -2.47, -2.11],\n",
              "        [-2.37, -2.25, -2.09,  ..., -2.46, -2.43, -2.11],\n",
              "        [-2.34, -2.31, -2.14,  ..., -2.44, -2.48, -2.14],\n",
              "        ...,\n",
              "        [-2.26, -2.25, -2.13,  ..., -2.36, -2.53, -2.17],\n",
              "        [-2.39, -2.30, -2.18,  ..., -2.38, -2.42, -2.11],\n",
              "        [-2.40, -2.25, -2.14,  ..., -2.38, -2.45, -2.23]], grad_fn=<IndexBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 532
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def nll(input, target): # this will cross entropy loss   # negative non-likelihood loss\n",
        "  return -input[range(target.shape[0]), target].mean()"
      ],
      "metadata": {
        "id": "W0ZnfBUBBAH8"
      },
      "execution_count": 533,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Pon5kkkpF5Aj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss = nll(sm_pred, y_train)\n",
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-lLmSkZZBAJ0",
        "outputId": "27f9365c-a05a-4ed5-baf3-829f1187e876"
      },
      "execution_count": 534,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.30, grad_fn=<NegBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 534
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Then use PyTorch's implementation.\n",
        "test_close(F.nll_loss(F.log_softmax(pred, -1), y_train), loss, 1e-3)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qX3HBWS9BAL9"
      },
      "execution_count": 535,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# In PyTorch, F.log_softmax and F.nll_loss are combined in one optimized function, F.cross_entropy.\n",
        "test_close(F.cross_entropy(pred, y_train), loss, 1e-3)\n"
      ],
      "metadata": {
        "id": "wU6E_D6jBAOl"
      },
      "execution_count": 536,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dHLTJNjcjSJK"
      },
      "execution_count": 536,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6CgF_RGnjSL-"
      },
      "execution_count": 536,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# basic training loop\n",
        "\n",
        "Basic training loop\n",
        "Basically the training loop repeats over the following steps:\n",
        "\n",
        " * get the output of the model on a batch of inputs\n",
        " * compare the output to the labels we have and compute a loss\n",
        " * calculate the gradients of the loss with respect to every parameter of the model\n",
        " * update said parameters with those gradients to make them a little bit better"
      ],
      "metadata": {
        "id": "FA2j3Gv5F6mO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_func = F.cross_entropy"
      ],
      "metadata": {
        "id": "482EP6mgF9bT"
      },
      "execution_count": 537,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bs = 50  # batch size\n",
        "xb = x_train[0:bs]  # a mini batch from x\n",
        "preds = model(xb)\n",
        "\n",
        "preds[0], preds.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebpHPoCYF95s",
        "outputId": "846664b8-8ed4-4a1b-e9d1-621c60ebb829"
      },
      "execution_count": 538,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([-0.05,  0.03,  0.22,  0.02,  0.00, -0.09, -0.04, -0.12, -0.15,  0.20], grad_fn=<SelectBackward0>),\n",
              " torch.Size([50, 10]))"
            ]
          },
          "metadata": {},
          "execution_count": 538
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "yb = y_train[0:bs]\n",
        "yb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JS0UuditF970",
        "outputId": "f97e53ca-f10a-42c2-882b-fe65c5476b2d"
      },
      "execution_count": 539,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([5, 0, 4, 1, 9, 2, 1, 3, 1, 4, 3, 5, 3, 6, 1, 7, 2, 8, 6, 9, 4, 0, 9, 1, 1, 2, 4, 3, 2, 7, 3, 8, 6, 9, 0, 5, 6, 0, 7,\n",
              "        6, 1, 8, 7, 9, 3, 9, 8, 5, 9, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 539
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_func(preds, yb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AdqBuZ52F99e",
        "outputId": "60de52d8-6a9d-4c27-d220-58aacba021b9"
      },
      "execution_count": 540,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.28, grad_fn=<NllLossBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 540
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds.argmax(dim=1) # for each rows in preds , find highest number"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8wQlEPfF9-2",
        "outputId": "c965a0a9-2fa0-48c1-8230-809f7f788e19"
      },
      "execution_count": 541,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2, 2, 4, 2, 2, 9, 2, 2, 1, 9, 9, 9, 2, 2, 1, 2, 2, 2, 9, 9, 2, 2, 9, 2, 2, 2, 2, 2, 2, 1, 9, 1, 2, 2, 2, 9, 2, 9, 2,\n",
              "        9, 9, 2, 9, 2, 9, 2, 2, 2, 2, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 541
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(out, yb):\n",
        "  return (out.argmax(dim = 1) == yb).float().mean()"
      ],
      "metadata": {
        "id": "zqWDJEHAF-An"
      },
      "execution_count": 542,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy(preds, yb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lj2mupU0F-Cd",
        "outputId": "fbc3b927-a685-44fe-e82f-5125b8f1c0fb"
      },
      "execution_count": 543,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.16)"
            ]
          },
          "metadata": {},
          "execution_count": 543
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.5\n",
        "epochs = 3"
      ],
      "metadata": {
        "id": "s3LsXd7DF-FI"
      },
      "execution_count": 544,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def report(loss, preds, yb):\n",
        "  print(f\"{loss:.2f}, {accuracy(preds,yb):.2f}\")"
      ],
      "metadata": {
        "id": "XwMP9mc0ZBx5"
      },
      "execution_count": 545,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xb,yb = x_train[:bs],y_train[:bs]\n",
        "preds = model(xb)\n",
        "report(loss_func(preds, yb), preds, yb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RgHpDCmiZB0b",
        "outputId": "579c5143-0006-4336-c50a-92cbda1680f8"
      },
      "execution_count": 546,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.28, 0.16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "  for i in range(0, n, bs):\n",
        "    s = slice(i, min(n, i+bs))\n",
        "    xb, yb = x_train[s], y_train[s]\n",
        "    preds = model(xb)\n",
        "    loss = loss_func(preds, yb)\n",
        "    loss.backward()\n",
        "\n",
        "    with torch.no_grad():\n",
        "      for l in model.layers:\n",
        "        if( hasattr( l , 'weight')):\n",
        "          l.weight -= l.weight.grad * lr\n",
        "          l.bias -= l.bias.grad * lr\n",
        "\n",
        "          l.weight.grad.zero_()\n",
        "          l.bias.grad.zero_()\n",
        "\n",
        "  report(loss, preds, yb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4b_3-z6ZB2Q",
        "outputId": "4de2b524-3253-454b-c0c9-bde66c220e94"
      },
      "execution_count": 547,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.08, 0.96\n",
            "0.05, 0.98\n",
            "0.07, 0.96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using parameters and optim\n"
      ],
      "metadata": {
        "id": "LvjRvSOMsmUc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## parameters"
      ],
      "metadata": {
        "id": "9um3Xn-yspoS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m1 = nn.Module()\n",
        "m1, list(m1.parameters())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mp9sRhMxZB4k",
        "outputId": "7d50278a-32d5-45b2-8260-4d95b3fa9bc1"
      },
      "execution_count": 548,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Module(), [])"
            ]
          },
          "metadata": {},
          "execution_count": 548
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m1.foo = nn.Linear(3,4)  #  the number of neurons in a linear layer is determined by the number of output features.\n",
        "m1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2e8gw1yQZB6s",
        "outputId": "ef52209c-3c09-4809-c129-01f1784ea0be"
      },
      "execution_count": 549,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Module(\n",
              "  (foo): Linear(in_features=3, out_features=4, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 549
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(m1.named_children())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_LUelpKuZB9J",
        "outputId": "8a5e7bd7-6aba-4143-bfce-6019a66e9806"
      },
      "execution_count": 550,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('foo', Linear(in_features=3, out_features=4, bias=True))]"
            ]
          },
          "metadata": {},
          "execution_count": 550
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m1.named_children()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FcnwVkdeZB_T",
        "outputId": "4c7b8794-3bfb-4496-9385-a75bd35c3f06"
      },
      "execution_count": 551,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<generator object Module.named_children at 0x7a5df668c3c0>"
            ]
          },
          "metadata": {},
          "execution_count": 551
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(m1.parameters())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MzVAVIo3ZCBn",
        "outputId": "819aa78f-60ed-479b-9055-617d218313cc"
      },
      "execution_count": 552,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([[-0.24, -0.11,  0.46],\n",
              "         [-0.17, -0.46, -0.07],\n",
              "         [-0.29,  0.31,  0.08],\n",
              "         [-0.24,  0.13, -0.17]], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([ 0.01,  0.51, -0.11, -0.47], requires_grad=True)]"
            ]
          },
          "metadata": {},
          "execution_count": 552
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# multi layer perceptron\n",
        "\n",
        "class MLP(nn.Module):\n",
        "  def __init__(self, n_in, nh, n_out):\n",
        "    super().__init__()\n",
        "    self.l1 = nn.Linear(n_in,nh )\n",
        "    self.l2 = nn.Linear(nh, n_out)\n",
        "    self.relu = nn.ReLU()\n",
        "\n",
        "\n",
        "  def __call__(self, x):\n",
        "    return self.l2(self.relu(self.l1(x)))"
      ],
      "metadata": {
        "id": "UnADJPssZCDt"
      },
      "execution_count": 553,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MLP(m, nh, 10)\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OVLbFwYFHxGt",
        "outputId": "1a3fc018-a4c6-4c19-9d8d-25d92db82bab"
      },
      "execution_count": 554,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLP(\n",
              "  (l1): Linear(in_features=784, out_features=50, bias=True)\n",
              "  (l2): Linear(in_features=50, out_features=10, bias=True)\n",
              "  (relu): ReLU()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 554
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.l1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ol0NhBMcHxJM",
        "outputId": "25b6a9dd-5104-4885-e2b3-681903d40582"
      },
      "execution_count": 555,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=784, out_features=50, bias=True)"
            ]
          },
          "metadata": {},
          "execution_count": 555
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for name, l in model.named_children():\n",
        "  print(f\"{name}: {l}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29WWa9-xHxKz",
        "outputId": "25aaabd5-2647-49a0-fc27-748b25be04cb"
      },
      "execution_count": 556,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "l1: Linear(in_features=784, out_features=50, bias=True)\n",
            "l2: Linear(in_features=50, out_features=10, bias=True)\n",
            "relu: ReLU()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for p in model.parameters():   # parameters are `weights` + `bias`\n",
        "  print(p.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24nN-2UmHxMb",
        "outputId": "cd6357b3-d9a0-4f9e-8df4-3a2022c430c9"
      },
      "execution_count": 557,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([50, 784])\n",
            "torch.Size([50])\n",
            "torch.Size([10, 50])\n",
            "torch.Size([10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[l for l in model.children()]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMEkqHmnTCa1",
        "outputId": "5b031240-8e9e-49d1-e884-a7794618cd85"
      },
      "execution_count": 558,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Linear(in_features=784, out_features=50, bias=True),\n",
              " Linear(in_features=50, out_features=10, bias=True),\n",
              " ReLU()]"
            ]
          },
          "metadata": {},
          "execution_count": 558
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "torch.no_grad() is used to perform parameter updates without tracking gradients during this specific block of code.\n",
        "This is a common practice during the training loop when you have parts that involve updating the model parameters but don't need to be included\n",
        "in the gradient computation.\n",
        "\n",
        "\"\"\"\n",
        "def fit():\n",
        "  for epoch in range(epochs):\n",
        "    for i in range(0, n, bs):\n",
        "      s = slice(i , min(n, i+bs))\n",
        "      xb, yb = x_train[s], y_train[s]\n",
        "      preds = model(xb)\n",
        "\n",
        "      loss = loss_func(preds, yb)\n",
        "      loss.backward()  # it just computes gradients and stores gradients in `.grad`\n",
        "      with torch.no_grad():\n",
        "        for p in model.parameters():\n",
        "          p-= p.grad * lr   # manually updating parameters\n",
        "        model.zero_grad()  # to zero all gradients\n",
        "    report(loss, preds, yb)\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    but how does it know what paarameters and layers are automatically? it used a trick called __setattr__\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "fit()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZdLnbUyRHxPd",
        "outputId": "a464c387-e264-493c-ef7b-0e6c84f0c2f0"
      },
      "execution_count": 559,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.12, 0.96\n",
            "0.11, 0.98\n",
            "0.09, 0.96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Behind the scenes, PyTorch overrides the __setattr__ function in nn.Module so that the submodules you define are properly registered as parameters of the model.\n",
        "\n"
      ],
      "metadata": {
        "id": "pWTBM3IbO9Qu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#     but how does it know what paarameters and layers are automatically? it used a trick called __setattr__\n",
        "\n",
        "class MyModule:     # its by defult class MyModule(object)\n",
        "  def __init__(self, n_in, nh, n_out):\n",
        "    self._modules = {}\n",
        "    self.l1 = nn.Linear(n_in, nh)\n",
        "    self.l2 = nn.Linear(nh, n_out)\n",
        "\n",
        "\n",
        "  def __setattr__(self,k,v):\n",
        "        if not k.startswith(\"_\"): self._modules[k] = v  # to make sure its private  # it adds that attr in modules directory\n",
        "        super().__setattr__(k,v)\n",
        "\n",
        "        # every attibute you set like     self.l1 = nn.Linear(n_in, nh) , it\n",
        "\n",
        "  def __repr__(self): return f'{self._modules}'   # how it represents modules dic\n",
        "\n",
        "  def parameters(self):\n",
        "      for l in self._modules.values():   # go through each of modules.  value of modules is actual layers\n",
        "        yield from l.parameters()"
      ],
      "metadata": {
        "id": "jCk43FbqZCGe"
      },
      "execution_count": 560,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mdl = MyModule(m,nh,10)\n",
        "mdl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fT_mcq5SO-1J",
        "outputId": "1f2adfdc-3e11-4a74-b585-13675970904b"
      },
      "execution_count": 561,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'l1': Linear(in_features=784, out_features=50, bias=True), 'l2': Linear(in_features=50, out_features=10, bias=True)}"
            ]
          },
          "metadata": {},
          "execution_count": 561
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mdl._modules"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8iJ8N7rHO-3u",
        "outputId": "6ee9f038-18a5-45f6-f657-ee981e81459d"
      },
      "execution_count": 562,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'l1': Linear(in_features=784, out_features=50, bias=True),\n",
              " 'l2': Linear(in_features=50, out_features=10, bias=True)}"
            ]
          },
          "metadata": {},
          "execution_count": 562
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for p in mdl.parameters(): print(p.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zq8-5RulO-6A",
        "outputId": "41600e40-0457-4ba3-c846-ab9700f61cf6"
      },
      "execution_count": 563,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([50, 784])\n",
            "torch.Size([50])\n",
            "torch.Size([10, 50])\n",
            "torch.Size([10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def numbers_to_10():\n",
        "    for i in range(1, 11):\n",
        "        yield i\n",
        "\n",
        "def numbers_to_20():\n",
        "    yield from numbers_to_10()  # Yield values from another generator()..   if we dont use yield, values would be skipped\n",
        "    for i in range(11, 21):\n",
        "        yield i\n",
        "\n",
        "# for num in numbers_to_20():\n",
        "#     print(num)  # Outputs numbers 1 to 20\n",
        "\n",
        "list(numbers_to_20())"
      ],
      "metadata": {
        "id": "VkJ22jh1O-8X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e097a58a-427f-46be-9d31-150b01832593"
      },
      "execution_count": 564,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]"
            ]
          },
          "metadata": {},
          "execution_count": 564
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(numbers_to_10())"
      ],
      "metadata": {
        "id": "Dr8TYpQ_O--m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee182f63-7568-460d-e1fe-d03594bf6429"
      },
      "execution_count": 565,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]"
            ]
          },
          "metadata": {},
          "execution_count": 565
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "numbers_to_10()"
      ],
      "metadata": {
        "id": "BTLsxBHwO_Aw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ee2b9f4-d506-49e7-d350-094877a44f01"
      },
      "execution_count": 566,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<generator object numbers_to_10 at 0x7a5df663aff0>"
            ]
          },
          "metadata": {},
          "execution_count": 566
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2RNkeLywO_DK"
      },
      "execution_count": 566,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Registering modules"
      ],
      "metadata": {
        "id": "9uWNpUYHgQ9g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from functools import reduce"
      ],
      "metadata": {
        "id": "dCoZ7JWxO_Fd"
      },
      "execution_count": 567,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can use the original layers approach, but we have to register the modules.\n",
        "\n"
      ],
      "metadata": {
        "id": "Yfi3knfygflh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "layers = [  nn.Linear(m,nh),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(nh, 10)]\n",
        "layers"
      ],
      "metadata": {
        "id": "DCYYdL5nO_H9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d9ea9af-8946-4c29-d470-62781218b30b"
      },
      "execution_count": 568,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Linear(in_features=784, out_features=50, bias=True),\n",
              " ReLU(),\n",
              " Linear(in_features=50, out_features=10, bias=True)]"
            ]
          },
          "metadata": {},
          "execution_count": 568
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from functools import reduce\n"
      ],
      "metadata": {
        "id": "uX49F94Ir1tv"
      },
      "execution_count": 569,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(nn.Module):\n",
        "  def __init__(self, layers):\n",
        "    super().__init__()\n",
        "    self.layers = layers\n",
        "    for i,l in enumerate(self.layers):\n",
        "      self.add_module(f'layer_{i}', l)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return reduce(lambda val, layer: layer(val), self.layers, x)  # reduce(reduction_function, self.layers, x)\n",
        "\n",
        "\n",
        "\"\"\"result = reduce(reduction_function, self.layers, x)\n",
        "The reduce function is called with three arguments:\n",
        "\n",
        "reduction_function: The binary function to apply cumulatively.\n",
        "self.layers: The iterable (list of layers) to apply the function to.\n",
        "x: The initial value to start the accumulation.\n",
        "The reduce function iterates through the layers, applying the lambda function to the accumulated value (val) and the current layer, updating the accumulated\n",
        "value at each step. The final result is the output of the last layer applied to the initial input x.\"\"\""
      ],
      "metadata": {
        "id": "w3iG5vLEO_Kn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "b4c1e24c-c235-407e-a689-fb16fef71ad0"
      },
      "execution_count": 570,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'result = reduce(reduction_function, self.layers, x)\\nThe reduce function is called with three arguments:\\n\\nreduction_function: The binary function to apply cumulatively.\\nself.layers: The iterable (list of layers) to apply the function to.\\nx: The initial value to start the accumulation.\\nThe reduce function iterates through the layers, applying the lambda function to the accumulated value (val) and the current layer, updating the accumulated\\nvalue at each step. The final result is the output of the last layer applied to the initial input x.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 570
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model(layers)\n",
        "model"
      ],
      "metadata": {
        "id": "MYNxUo9IO_Nn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89ea2c7f-45d2-428c-cc54-af0a92773441"
      },
      "execution_count": 571,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model(\n",
              "  (layer_0): Linear(in_features=784, out_features=50, bias=True)\n",
              "  (layer_1): ReLU()\n",
              "  (layer_2): Linear(in_features=50, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 571
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s= [ 1,2,3]\n",
        "\n",
        "reduce( lambda x,y : x+y,s , 10)"
      ],
      "metadata": {
        "id": "IAspKFE0O_QM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "819910df-607f-4ade-c3e1-8d32695e8998"
      },
      "execution_count": 572,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16"
            ]
          },
          "metadata": {},
          "execution_count": 572
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model(xb).shape"
      ],
      "metadata": {
        "id": "NtJzEim4O_Ro",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99acb502-9fbd-4558-92ec-1a8353964d2b"
      },
      "execution_count": 573,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([50, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 573
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ShabzRwvO_Uv"
      },
      "execution_count": 573,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KQgrxXr5t1Gk"
      },
      "execution_count": 573,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# nn.ModuleList\n",
        "  nn.ModuleList does this for us"
      ],
      "metadata": {
        "id": "lKAFmtrGt1St"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SequentialModel(nn.Module):\n",
        "  def __init__(self, layers):\n",
        "    super().__init__()\n",
        "    self.layers = nn.ModuleList(layers)# replaces `self.layers = layers; for i,l in enumerate(self.layers): self.add_module(f'layer_{i}', l)\n",
        "\n",
        "  # def forward(self,x):\n",
        "  #   for l in self.layers:x = l(x);\n",
        "  #   return x\n",
        "\n",
        "  def forward(self,x):\n",
        "    return reduce( lambda v,l :l(v), self.layers, x )"
      ],
      "metadata": {
        "id": "X39pxz57t1gU"
      },
      "execution_count": 574,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SequentialModel(layers)\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-KzTg-Dt1iX",
        "outputId": "388a2aee-e7f0-4961-f18a-8813c148e9ca"
      },
      "execution_count": 575,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SequentialModel(\n",
              "  (layers): ModuleList(\n",
              "    (0): Linear(in_features=784, out_features=50, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=50, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 575
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fit()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKooCATet1kb",
        "outputId": "fc019409-8fcd-4daa-982f-683163f380f2"
      },
      "execution_count": 576,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.13, 0.92\n",
            "0.10, 0.96\n",
            "0.08, 0.96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sHMn8B7vt1mt"
      },
      "execution_count": 576,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = [1,2,3,4,5,6]\n",
        "list(filter(lambda x : x%2 != 0 , x))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Vayrt3t0elh",
        "outputId": "1904038e-6229-489e-c89d-c04044240bc9"
      },
      "execution_count": 577,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 3, 5]"
            ]
          },
          "metadata": {},
          "execution_count": 577
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w93afbOi0eoR"
      },
      "execution_count": 577,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# nn.Sequential\n",
        "nn.Sequential does same by default\n"
      ],
      "metadata": {
        "id": "YEUPxdZJx4P0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.Sequential(nn.Linear(m,nh), nn.ReLU(), nn.Linear(nh,10))\n",
        "model\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4ugDI75t1oY",
        "outputId": "f799a981-ce0b-4f61-fcfa-c896e7a2257f"
      },
      "execution_count": 578,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Linear(in_features=784, out_features=50, bias=True)\n",
              "  (1): ReLU()\n",
              "  (2): Linear(in_features=50, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 578
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fit()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQGkZnTAt1qR",
        "outputId": "68aea526-5a23-4624-b102-aeaff8ad7292"
      },
      "execution_count": 579,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.16, 0.96\n",
            "0.10, 0.96\n",
            "0.05, 0.98\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_func(model(xb), yb),      accuracy(model(xb), yb)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQKMx_Kpt1sR",
        "outputId": "d83aaf80-e03e-4795-9d83-597f295b47a9"
      },
      "execution_count": 580,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.02, grad_fn=<NllLossBackward0>), tensor(1.))"
            ]
          },
          "metadata": {},
          "execution_count": 580
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X3xmFBi0t1uV"
      },
      "execution_count": 580,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# optim"
      ],
      "metadata": {
        "id": "uo-qg4s1KCll"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Optimizer:\n",
        "  def __init__(self, params, lr = 0.5):\n",
        "    self.params, self.lr = list(params), lr\n",
        "\n",
        "  def step(self):\n",
        "    with torch.no_grad():\n",
        "      for p in self.params:\n",
        "        p -= p.grad * self.lr\n",
        "\n",
        "  def zero_grad(self):\n",
        "    for p in self.params:\n",
        "      p.grad.data.zero_()\n"
      ],
      "metadata": {
        "id": "l3O760FUt1xO"
      },
      "execution_count": 581,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.Sequential(\n",
        "    nn.Linear(m,nh),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(nh, 10)\n",
        ")"
      ],
      "metadata": {
        "id": "aADh8sEkKBQI"
      },
      "execution_count": 582,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "opt = Optimizer(model.parameters())"
      ],
      "metadata": {
        "id": "tCfG2Y_OKBSb"
      },
      "execution_count": 583,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "  for i in range(0 , n, bs):\n",
        "    s = slice(i, min(i+bs , n))\n",
        "\n",
        "    xb,yb = x_train[s], y_train[s]\n",
        "    preds = model(xb)\n",
        "\n",
        "    loss = loss_func(preds, yb)\n",
        "    loss.backward()  # computes gradients\n",
        "\n",
        "    opt.step()\n",
        "    opt.zero_grad()\n",
        "  report(loss, preds, yb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OXVi-ET0KBU6",
        "outputId": "edbf35a0-fd53-49c5-cb15-f8bfb969d784"
      },
      "execution_count": 584,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.10, 0.98\n",
            "0.06, 1.00\n",
            "0.03, 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyTorch already provides this exact functionality in optim.SGD (it also handles stuff like momentum, which we'll look at later)"
      ],
      "metadata": {
        "id": "HdiUZjE0NNGO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import optim"
      ],
      "metadata": {
        "id": "-o9WK1-HKBYI"
      },
      "execution_count": 585,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model():\n",
        "  model = nn.Sequential(\n",
        "      nn.Linear(m,nh),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(nh, 10)\n",
        "  )\n",
        "  return model, optim.SGD(model.parameters(), lr = lr)"
      ],
      "metadata": {
        "id": "NO9UwiXSKBaE"
      },
      "execution_count": 586,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model, opt = get_model()\n",
        "loss_func( model(xb), yb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fSC_Kk75KBb3",
        "outputId": "f0febb93-a621-4882-e9ef-939a023cfee1"
      },
      "execution_count": 587,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.31, grad_fn=<NllLossBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 587
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "    for i in range(0, n, bs):\n",
        "        s = slice(i, min(n,i+bs))\n",
        "        xb,yb = x_train[s],y_train[s]\n",
        "        preds = model(xb)\n",
        "        loss = loss_func(preds, yb)\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        opt.zero_grad()\n",
        "    report(loss, preds, yb)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V5lBiumGKBdl",
        "outputId": "360b5ac9-c7a3-4301-a4f6-398a843298e9"
      },
      "execution_count": 588,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.15, 0.92\n",
            "0.11, 0.96\n",
            "0.07, 0.96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5T5uZC0TOAyZ"
      },
      "execution_count": 588,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset and DataLoader\n"
      ],
      "metadata": {
        "id": "cN5hWwD3OFC2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset\n",
        "  It's clunky to iterate through minibatches of x and y values separately:\n",
        "  \n",
        "  \n",
        "* `xb,yb = x_train[s],y_train[s]`\n",
        "  instead let's do both steps together\n",
        "  `xb, yb = train_ds[s]`\n"
      ],
      "metadata": {
        "id": "mNYO0F2DOgRi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Dataset():\n",
        "  def __init__( self,x,y):\n",
        "    self.x, self.y = x,y\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.x)\n",
        "\n",
        "  def __getitem__(self, i):\n",
        "    return self.x[i], self.y[i]  # it will be called automatically whenever [] are used i.e. x[i]"
      ],
      "metadata": {
        "id": "OliMs2JLOBnW"
      },
      "execution_count": 589,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = Dataset(x_train, y_train)\n",
        "len(train_ds), len(train_ds[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DD3ydnA2OBpn",
        "outputId": "24cda627-6209-448e-c6a4-d31f090c1b8e"
      },
      "execution_count": 590,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 590
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds, valid_ds = Dataset(x_train, y_train), Dataset(x_valid , y_valid)\n",
        "assert len(train_ds) == len(x_train)\n",
        "assert len(valid_ds) == len(x_valid)"
      ],
      "metadata": {
        "id": "R5nIrLsNOBry"
      },
      "execution_count": 591,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xb, yb = train_ds[:5]\n",
        "assert xb.shape == (5, 28*28)\n",
        "assert yb.shape == (5,)"
      ],
      "metadata": {
        "id": "vMQ-5PypOBuO"
      },
      "execution_count": 592,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model, opt = get_model()"
      ],
      "metadata": {
        "id": "IRO0UQwgaQT1"
      },
      "execution_count": 593,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "    for i in range(0, n, bs):\n",
        "        xb,yb = train_ds[i: min(n,i+bs)]\n",
        "        preds = model(xb)\n",
        "        loss = loss_func(preds, yb)\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        opt.zero_grad()\n",
        "    report(loss, preds, yb)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ZrP3w5EOBwI",
        "outputId": "11b6b73d-8f2c-4247-f7a5-0134dba32295"
      },
      "execution_count": 594,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.14, 0.94\n",
            "0.10, 0.96\n",
            "0.08, 0.96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DataLoader(iterator)\n",
        "to replace\n",
        "\n",
        "`    for i in range(0, n, bs):`\n",
        "`        xb,yb = train_ds[i: min(n,i+bs)]  ` # dataloader does this\n",
        "\n",
        "\n",
        "\n",
        "* dataloader is an iterator. Iterator has a class that has dunder iterator methof( __iter__()\n",
        "\n",
        "  \n"
      ],
      "metadata": {
        "id": "nkTBY_Q3a6Kf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DataLoader(): # will return a batch of elements\n",
        "  def __init__(self, ds, bs):\n",
        "    self.ds, self.bs = ds, bs\n",
        "\n",
        "\n",
        "  def __iter__(self):\n",
        "    for i in range(0, len(self.ds), self.bs):\n",
        "      yield self.ds[i : i+self.bs]\n",
        "\n"
      ],
      "metadata": {
        "id": "kJOhEyS8OByU"
      },
      "execution_count": 595,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dl = DataLoader(train_ds, bs)\n",
        "valid_dl = DataLoader(valid_ds, bs)"
      ],
      "metadata": {
        "id": "ziMQCMRAOB0O"
      },
      "execution_count": 596,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "next(iter(valid_dl))[0].shape, next(iter(valid_dl))[1].shape"
      ],
      "metadata": {
        "id": "FxiaUo1pCU0H",
        "outputId": "497ac270-9103-49fd-adf1-531abbb88acd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 597,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([50, 784]), torch.Size([50]))"
            ]
          },
          "metadata": {},
          "execution_count": 597
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "next(iter(valid_dl))[0].shape, next(iter(valid_dl))[1].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UAiVTWQ7OB2x",
        "outputId": "6707e15f-09d4-4657-c133-5dbf6ac43eeb"
      },
      "execution_count": 598,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([50, 784]), torch.Size([50]))"
            ]
          },
          "metadata": {},
          "execution_count": 598
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xb,yb = next(iter(valid_dl))\n",
        "xb.shape, yb.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ZrhgP3cOB5g",
        "outputId": "f6c94315-2834-489f-d621-92e0d70db914"
      },
      "execution_count": 599,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([50, 784]), torch.Size([50]))"
            ]
          },
          "metadata": {},
          "execution_count": 599
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "yb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iN-h2C-Efdq_",
        "outputId": "4ffbd89f-99d1-4378-d7c7-24f55c59244a"
      },
      "execution_count": 600,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([3, 8, 6, 9, 6, 4, 5, 3, 8, 4, 5, 2, 3, 8, 4, 8, 1, 5, 0, 5, 9, 7, 4, 1, 0, 3, 0, 6, 2, 9, 9, 4, 1, 3, 6, 8, 0, 7, 7,\n",
              "        6, 8, 9, 0, 3, 8, 3, 7, 7, 8, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 600
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(xb[0].view(28,28))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "iIAzOwOKff2n",
        "outputId": "341dfc20-89a2-478e-83ce-84ab43df95b6"
      },
      "execution_count": 601,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7a5df6424f10>"
            ]
          },
          "metadata": {},
          "execution_count": 601
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model,opt = get_model()"
      ],
      "metadata": {
        "id": "rJHBEoBrfgTw"
      },
      "execution_count": 602,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fit():\n",
        "    for epoch in range(epochs):\n",
        "        for xb,yb in train_dl:  # getting batches\n",
        "            preds = model(xb)\n",
        "            loss = loss_func(preds, yb)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            opt.zero_grad()\n",
        "        report(loss, preds, yb)\n"
      ],
      "metadata": {
        "id": "KKUrQqQQfgV9"
      },
      "execution_count": 603,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fit()\n",
        "loss_func(model(xb), yb), accuracy(model(xb), yb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9ms0ylLfgYG",
        "outputId": "542a8323-85b5-4b3e-a7bf-35a081f10048"
      },
      "execution_count": 604,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.12, 0.96\n",
            "0.10, 0.98\n",
            "0.10, 0.96\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.05, grad_fn=<NllLossBackward0>), tensor(1.))"
            ]
          },
          "metadata": {},
          "execution_count": 604
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random sampling\n",
        "we want our training set to be randomized"
      ],
      "metadata": {
        "id": "bB5R7DhymB1r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random"
      ],
      "metadata": {
        "id": "2iJF0xmQfgaD"
      },
      "execution_count": 605,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Sampler():\n",
        "  def __init__(self, ds, shuffle = False):\n",
        "    self.n, self.shuffle = len(ds), shuffle\n",
        "\n",
        "  def __iter__(self):\n",
        "    res = list(range(self.n))\n",
        "    # print(f'before:{res}')\n",
        "\n",
        "    if self.shuffle:\n",
        "      random.shuffle(res)\n",
        "    # print(f'Later:{res}')\n",
        "    return iter(res)"
      ],
      "metadata": {
        "id": "724wb-oafgb8"
      },
      "execution_count": 606,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ss =Sampler(train_ds)\n",
        "ss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zOKq0iBGfgfp",
        "outputId": "270b9a19-4c0a-457d-e4a4-240dc6191dcd"
      },
      "execution_count": 607,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.Sampler at 0x7a5df64a4d30>"
            ]
          },
          "metadata": {},
          "execution_count": 607
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "it = iter(ss)  # calling ___iter__()\n",
        "list(it)[:5]   # these are indexes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8BEV8hEfgh2",
        "outputId": "27052d2b-7305-4f45-cc0f-84f7f0057afe"
      },
      "execution_count": 608,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 2, 3, 4]"
            ]
          },
          "metadata": {},
          "execution_count": 608
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import islice"
      ],
      "metadata": {
        "id": "f7VmJyZzq5Op"
      },
      "execution_count": 609,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list(islice(ss,5)) # first 5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_GKnf9yfgj3",
        "outputId": "a64895bc-6a1f-4227-fd9e-def393d98e1e"
      },
      "execution_count": 610,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 2, 3, 4]"
            ]
          },
          "metadata": {},
          "execution_count": 610
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s =Sampler(train_ds, True)\n",
        "list(islice(s,5)) # first 5"
      ],
      "metadata": {
        "id": "oCRhOF8rq4in",
        "outputId": "d0804218-7055-4802-df69-0ad9629fdb4c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 611,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3607, 959, 19705, 14588, 22286]"
            ]
          },
          "metadata": {},
          "execution_count": 611
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import fastcore.all as fc"
      ],
      "metadata": {
        "id": "oJrNXAlefgms"
      },
      "execution_count": 612,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## creating batch sampler"
      ],
      "metadata": {
        "id": "T1eOXGo2rYVR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BatchSampler():  # it will do islice for us\n",
        "  def __init__(self, sampler, bs, drop_last = False):\n",
        "    # sampler, bs, drop_last  = self.sampler, self.bs, self.drop_last\n",
        "    fc.store_attr()\n",
        "\n",
        "  def __iter__(self):\n",
        "    yield from fc.chunked(iter(self.sampler), self.bs, drop_last = self.drop_last)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "sqdqZ2UsrUii"
      },
      "execution_count": 613,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batchs = BatchSampler( ss, 4)\n",
        "\n",
        "list(islice(batchs,5))"
      ],
      "metadata": {
        "id": "HxPrXi4srUkv",
        "outputId": "d04e40f2-8f7c-4cc7-fa7a-fb47237806ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 614,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0, 1, 2, 3],\n",
              " [4, 5, 6, 7],\n",
              " [8, 9, 10, 11],\n",
              " [12, 13, 14, 15],\n",
              " [16, 17, 18, 19]]"
            ]
          },
          "metadata": {},
          "execution_count": 614
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def collate(b):\n",
        "    xs,ys = zip(*b)  # grab batches,, separate x and y separately and then stack them as tensors making x as a single tensor and y as an another\n",
        "    return torch.stack(xs),torch.stack(ys)\n",
        "\n",
        "\n",
        "    \"\"\"the zip function is used to combine elements from multiple iterables (in this case, tuples) into tuples.\n",
        "    The * operator is used to unpack the list b and pass its elements as separate arguments to zip. So, zip(*b) essentially transposes the list of batches.\n",
        "    \"\"\""
      ],
      "metadata": {
        "id": "K_h5JKTErUm4"
      },
      "execution_count": 615,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "tensor1 = torch.tensor([1, 2, 3])\n",
        "tensor2 = torch.tensor([4, 5, 6])\n",
        "tensor3 = torch.tensor([7, 8, 9])\n",
        "\n",
        "# Stack tensors along a new dimension (default is dim=0)\n",
        "stacked_tensor = torch.stack([tensor1, tensor2, tensor3])\n",
        "\n",
        "print(stacked_tensor)"
      ],
      "metadata": {
        "id": "WndyAjr1rUpS",
        "outputId": "d739cb24-17b7-436f-9292-1ffa40fcb027",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 616,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6],\n",
            "        [7, 8, 9]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DataLoader():\n",
        "    def __init__(self, ds, batchs, collate_fn=collate):\n",
        "      fc.store_attr()\n",
        "    def __iter__(self):\n",
        "      yield from (self.collate_fn(self.ds[i] for i in b) for b in self.batchs) # self.batchs batch_sampler will give indices # self.ds[i] getting item"
      ],
      "metadata": {
        "id": "O2tJJlCvrUq_"
      },
      "execution_count": 617,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_samp = BatchSampler(Sampler(train_ds, shuffle=True ), bs)\n",
        "valid_samp = BatchSampler(Sampler(valid_ds, shuffle=False), bs)"
      ],
      "metadata": {
        "id": "NGyvpnf6rUtq"
      },
      "execution_count": 618,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# self.ds[i] for i in b) for b in self.batchs\n",
        "o = next(iter(train_samp))\n",
        "o   # this is what batch_sample creates"
      ],
      "metadata": {
        "id": "tvRNoPDyM_aI",
        "outputId": "b08e1a42-e036-404e-e5dc-717164710bd8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 619,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[20144,\n",
              " 20020,\n",
              " 34678,\n",
              " 14979,\n",
              " 44166,\n",
              " 24545,\n",
              " 47618,\n",
              " 30066,\n",
              " 40363,\n",
              " 23664,\n",
              " 29162,\n",
              " 15340,\n",
              " 39245,\n",
              " 34744,\n",
              " 16846,\n",
              " 43035,\n",
              " 23548,\n",
              " 28083,\n",
              " 12788,\n",
              " 19573,\n",
              " 14897,\n",
              " 6984,\n",
              " 41682,\n",
              " 28032,\n",
              " 41707,\n",
              " 35295,\n",
              " 37646,\n",
              " 15856,\n",
              " 28262,\n",
              " 43343,\n",
              " 9552,\n",
              " 4540,\n",
              " 6745,\n",
              " 43969,\n",
              " 33965,\n",
              " 44672,\n",
              " 15806,\n",
              " 19412,\n",
              " 43168,\n",
              " 20684,\n",
              " 27890,\n",
              " 28888,\n",
              " 9887,\n",
              " 13670,\n",
              " 29404,\n",
              " 47858,\n",
              " 13075,\n",
              " 41261,\n",
              " 37676,\n",
              " 47202]"
            ]
          },
          "metadata": {},
          "execution_count": 619
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.array([train_ds[i] for i in o]).shape"
      ],
      "metadata": {
        "id": "7X5M9uk68gk9",
        "outputId": "a6926aac-899d-4b57-f2b7-46eaccdb5e6e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 620,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-620-178f71c5f8d3>:1: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  np.array([train_ds[i] for i in o]).shape\n",
            "<ipython-input-620-178f71c5f8d3>:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  np.array([train_ds[i] for i in o]).shape\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 620
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.array([train_ds[i] for i in o])[0] # xs, ys"
      ],
      "metadata": {
        "id": "VOJ571vf8gnL",
        "outputId": "cd893171-6df7-4d75-e2c0-9a12e4773c5a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 621,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-621-a6d41d8547c1>:1: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  np.array([train_ds[i] for i in o])[0] # xs, ys\n",
            "<ipython-input-621-a6d41d8547c1>:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  np.array([train_ds[i] for i in o])[0] # xs, ys\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([tensor([0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,\n",
              "               0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,\n",
              "               0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,\n",
              "               0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,\n",
              "               0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,\n",
              "               0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,\n",
              "               0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,\n",
              "               0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,\n",
              "               0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,\n",
              "               0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.01, 0.65, 1.00, 0.30, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.27, 0.15, 0.00,\n",
              "               0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.37, 0.99, 0.99, 0.33,\n",
              "               0.00, 0.00, 0.00, 0.00, 0.00, 0.25, 0.96, 0.82, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,\n",
              "               0.00, 0.00, 0.00, 0.00, 0.02, 0.75, 0.99, 0.84, 0.03, 0.00, 0.00, 0.00, 0.00, 0.00, 0.80, 0.99, 0.52, 0.00, 0.00,\n",
              "               0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.43, 0.99, 0.99, 0.37, 0.00, 0.00,\n",
              "               0.00, 0.00, 0.00, 0.00, 0.96, 0.99, 0.44, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,\n",
              "               0.00, 0.00, 0.06, 0.88, 0.99, 0.73, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.96, 0.99, 0.14, 0.00, 0.00, 0.00,\n",
              "               0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.40, 0.99, 0.99, 0.52, 0.00, 0.00, 0.00, 0.00,\n",
              "               0.00, 0.00, 0.23, 0.98, 0.99, 0.14, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,\n",
              "               0.00, 0.61, 0.99, 0.98, 0.21, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.55, 0.99, 0.99, 0.14, 0.00, 0.00, 0.00, 0.00,\n",
              "               0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.07, 0.89, 0.99, 0.96, 0.09, 0.00, 0.00, 0.00, 0.00, 0.00,\n",
              "               0.01, 0.87, 0.99, 0.86, 0.05, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,\n",
              "               0.63, 0.99, 0.99, 0.95, 0.70, 0.25, 0.23, 0.20, 0.00, 0.18, 0.99, 0.99, 0.90, 0.08, 0.00, 0.00, 0.00, 0.00, 0.00,\n",
              "               0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.11, 0.82, 0.99, 0.99, 0.99, 0.99, 0.99, 0.98, 0.87, 0.96,\n",
              "               0.99, 0.99, 0.95, 0.11, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,\n",
              "               0.08, 0.56, 0.87, 0.95, 0.99, 0.99, 0.99, 0.99, 0.99, 0.99, 0.87, 0.17, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,\n",
              "               0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.14, 0.23, 0.23, 0.23, 0.28, 0.99, 0.99,\n",
              "               0.44, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,\n",
              "               0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.20, 0.99, 0.99, 0.04, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,\n",
              "               0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.42, 0.99, 0.99, 0.16,\n",
              "               0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,\n",
              "               0.00, 0.00, 0.00, 0.00, 0.00, 0.76, 0.99, 0.80, 0.02, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,\n",
              "               0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.07, 0.89, 0.99, 0.36, 0.00, 0.00,\n",
              "               0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,\n",
              "               0.00, 0.00, 0.00, 0.60, 0.99, 0.93, 0.16, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,\n",
              "               0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.16, 0.90, 0.98, 0.32, 0.00, 0.00, 0.00, 0.00,\n",
              "               0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,\n",
              "               0.00, 0.85, 0.99, 0.76, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,\n",
              "               0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.40, 0.78, 0.07, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,\n",
              "               0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,\n",
              "               0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,\n",
              "               0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,\n",
              "               0.00, 0.00, 0.00, 0.00, 0.00])                                                                                   ,\n",
              "       tensor(4)], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 621
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p =[train_ds[i] for i in o]\n",
        "p[0]"
      ],
      "metadata": {
        "id": "hloRqdfGBoba",
        "outputId": "78893905-1b0c-4e2f-b45a-02272053ee62",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 622,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,\n",
              "         0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,\n",
              "         0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,\n",
              "         0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,\n",
              "         0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,\n",
              "         0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,\n",
              "         0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,\n",
              "         0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,\n",
              "         0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,\n",
              "         0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.01, 0.65, 1.00, 0.30, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.27, 0.15, 0.00,\n",
              "         0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.37, 0.99, 0.99, 0.33,\n",
              "         0.00, 0.00, 0.00, 0.00, 0.00, 0.25, 0.96, 0.82, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,\n",
              "         0.00, 0.00, 0.00, 0.00, 0.02, 0.75, 0.99, 0.84, 0.03, 0.00, 0.00, 0.00, 0.00, 0.00, 0.80, 0.99, 0.52, 0.00, 0.00,\n",
              "         0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.43, 0.99, 0.99, 0.37, 0.00, 0.00,\n",
              "         0.00, 0.00, 0.00, 0.00, 0.96, 0.99, 0.44, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,\n",
              "         0.00, 0.00, 0.06, 0.88, 0.99, 0.73, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.96, 0.99, 0.14, 0.00, 0.00, 0.00,\n",
              "         0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.40, 0.99, 0.99, 0.52, 0.00, 0.00, 0.00, 0.00,\n",
              "         0.00, 0.00, 0.23, 0.98, 0.99, 0.14, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,\n",
              "         0.00, 0.61, 0.99, 0.98, 0.21, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.55, 0.99, 0.99, 0.14, 0.00, 0.00, 0.00, 0.00,\n",
              "         0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.07, 0.89, 0.99, 0.96, 0.09, 0.00, 0.00, 0.00, 0.00, 0.00,\n",
              "         0.01, 0.87, 0.99, 0.86, 0.05, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,\n",
              "         0.63, 0.99, 0.99, 0.95, 0.70, 0.25, 0.23, 0.20, 0.00, 0.18, 0.99, 0.99, 0.90, 0.08, 0.00, 0.00, 0.00, 0.00, 0.00,\n",
              "         0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.11, 0.82, 0.99, 0.99, 0.99, 0.99, 0.99, 0.98, 0.87, 0.96,\n",
              "         0.99, 0.99, 0.95, 0.11, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,\n",
              "         0.08, 0.56, 0.87, 0.95, 0.99, 0.99, 0.99, 0.99, 0.99, 0.99, 0.87, 0.17, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,\n",
              "         0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.14, 0.23, 0.23, 0.23, 0.28, 0.99, 0.99,\n",
              "         0.44, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,\n",
              "         0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.20, 0.99, 0.99, 0.04, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,\n",
              "         0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.42, 0.99, 0.99, 0.16,\n",
              "         0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,\n",
              "         0.00, 0.00, 0.00, 0.00, 0.00, 0.76, 0.99, 0.80, 0.02, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,\n",
              "         0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.07, 0.89, 0.99, 0.36, 0.00, 0.00,\n",
              "         0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,\n",
              "         0.00, 0.00, 0.00, 0.60, 0.99, 0.93, 0.16, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,\n",
              "         0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.16, 0.90, 0.98, 0.32, 0.00, 0.00, 0.00, 0.00,\n",
              "         0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,\n",
              "         0.00, 0.85, 0.99, 0.76, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,\n",
              "         0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.40, 0.78, 0.07, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,\n",
              "         0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,\n",
              "         0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,\n",
              "         0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,\n",
              "         0.00, 0.00, 0.00, 0.00, 0.00]),\n",
              " tensor(4))"
            ]
          },
          "metadata": {},
          "execution_count": 622
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(p), len(p[0])"
      ],
      "metadata": {
        "id": "HeDzvr3RGOi6",
        "outputId": "68e69ece-936a-4f5d-8de2-b8fb4fabf67c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 623,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 623
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xs, ys = zip(*p)\n"
      ],
      "metadata": {
        "id": "QhM4MQBt8gp5"
      },
      "execution_count": 624,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.tensor(xs).size(), torch.tensor(ys).size()  # without stacking"
      ],
      "metadata": {
        "id": "sbZE5AMfEsxf"
      },
      "execution_count": 626,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.stack(xs).size(), torch.stack(ys).size()"
      ],
      "metadata": {
        "id": "K4_dXvEIEwkY",
        "outputId": "67477970-3b92-4aaf-a16b-a78969f66d16",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 627,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([50, 784]), torch.Size([50]))"
            ]
          },
          "metadata": {},
          "execution_count": 627
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FtDuz5vXEszh"
      },
      "execution_count": 627,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "678BfJI8Es2Z"
      },
      "execution_count": 627,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def example_function(a, b, c):\n",
        "    print(a, b, c)\n",
        "\n",
        "args = [1, 2, 3]\n",
        "\n",
        "# Using * to unpack the list into function arguments\n",
        "example_function(*args)"
      ],
      "metadata": {
        "id": "Mv5yG78MD8S7",
        "outputId": "34adf4fe-35f2-4486-a916-da743f50af07",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 628,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 2 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aaeICvaLB8mw"
      },
      "execution_count": 628,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Vo4kDB-PB8pl"
      },
      "execution_count": 628,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.array(list(iter(train_samp))).shape"
      ],
      "metadata": {
        "id": "BLK4jlEN1lS9",
        "outputId": "41b60626-0ad2-4050-ae5a-ae9f3af605cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 629,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 50)"
            ]
          },
          "metadata": {},
          "execution_count": 629
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.array(list(iter(train_samp)))[0]"
      ],
      "metadata": {
        "id": "U5k3UNNW5b7I",
        "outputId": "f680219d-4e9e-4482-94c6-f3a79ee5d69d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 630,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([20111,  6448, 20764,  1895,  6725, 44086, 29054, 34679,   986, 42567, 25243, 38133, 44175, 43491, 47743, 17973,\n",
              "       35656,  4618, 48364, 15644, 36065,   349, 33957, 36475,  8603, 38883, 30213, 41554, 32717,  6665, 30020, 33144,\n",
              "       43367,  7620,  8919, 41714, 30702, 44084, 12445, 14547,  3006, 26759,  8096,  4671, 24657, 10400, 37957, 30207,\n",
              "       23102,  7096])"
            ]
          },
          "metadata": {},
          "execution_count": 630
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def collate(b):\n",
        "    xs,ys = zip(*b)  # grab batches,, separate x and y separately and then stack them as tensors\n",
        "    return torch.stack(xs),torch.stack(ys)"
      ],
      "metadata": {
        "id": "_moKFTJaBbmH"
      },
      "execution_count": 631,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Txr57Vi4BbqB"
      },
      "execution_count": 631,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_i5mlnBEBbrj"
      },
      "execution_count": 631,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dl = DataLoader(train_ds, batchs=train_samp)\n",
        "valid_dl = DataLoader(valid_ds, batchs=valid_samp)"
      ],
      "metadata": {
        "id": "E62MGwvUrUvW"
      },
      "execution_count": 632,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xb,yb = next(iter(valid_dl))\n",
        "plt.imshow(xb[0].view(28,28))\n",
        "yb[0]"
      ],
      "metadata": {
        "id": "1jFCqWgOrUxk",
        "outputId": "59486bd6-be98-4b54-d6dd-a7cee6833fe3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        }
      },
      "execution_count": 633,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3)"
            ]
          },
          "metadata": {},
          "execution_count": 633
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xb.shape,yb.shape\n"
      ],
      "metadata": {
        "id": "Crz5MZOv5hbp",
        "outputId": "06ba097a-6d11-4cb0-ef88-6290cf061341",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 634,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([50, 784]), torch.Size([50]))"
            ]
          },
          "metadata": {},
          "execution_count": 634
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model,opt = get_model()\n"
      ],
      "metadata": {
        "id": "qsQ9gWvN5oyY"
      },
      "execution_count": 635,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fit()"
      ],
      "metadata": {
        "id": "_4y7Vp8m5o0o",
        "outputId": "352ae256-2712-4d95-b81f-6a039c57d761",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 636,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.24, 0.88\n",
            "0.07, 0.94\n",
            "0.15, 0.96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multiprocessing DataLoader\n"
      ],
      "metadata": {
        "id": "r22WKc105tT_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.multiprocessing as mp\n",
        "from fastcore.basics import store_attr"
      ],
      "metadata": {
        "id": "kXPF2bzA5o22"
      },
      "execution_count": 642,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds[[3,6,8,1]] # identical to calling __getitem__"
      ],
      "metadata": {
        "id": "Sjd2bkG75o5r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "938d1c8f-e185-43b0-f18a-a8f747dc1b6e"
      },
      "execution_count": 646,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
              " tensor([1, 1, 1, 0]))"
            ]
          },
          "metadata": {},
          "execution_count": 646
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds.__getitem__( [ 3,6,8,1])"
      ],
      "metadata": {
        "id": "irS1N_3h5o79",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e657fbc-bb9d-492d-dac6-e894d23f8cbf"
      },
      "execution_count": 647,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
              " tensor([1, 1, 1, 0]))"
            ]
          },
          "metadata": {},
          "execution_count": 647
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x,y = (train_ds[[3,6,8,1]])\n"
      ],
      "metadata": {
        "id": "4ZITrYCmG0l2"
      },
      "execution_count": 645,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for o in map(train_ds.__getitem__, ([3,6],[8,1])): print(o)"
      ],
      "metadata": {
        "id": "nNaFAO2eG-Jt",
        "outputId": "569f2dcf-a5bb-43d5-978d-adeac969dd9f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 641,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([1, 1]))\n",
            "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([1, 0]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AJPLm7LFG-MF"
      },
      "execution_count": 641,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1YEqbtjDG-OV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IZ3dv2pmG-RY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}