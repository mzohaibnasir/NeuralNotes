{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOCXOzdqdML3UfYB23YQZ1y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mzohaibnasir/NeuralNotes/blob/main/03_deepDiveIntoBasics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Minibatch Training"
      ],
      "metadata": {
        "id": "TvS7nn4_nePl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle,gzip,math,os,time,shutil,torch,matplotlib as mpl,numpy as np,matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "from torch import tensor,nn\n",
        "import torch.nn.functional as F\n",
        "from fastcore.test import test_close\n"
      ],
      "metadata": {
        "id": "gc0rwmBVnh2w"
      },
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MNIST_URL='https://github.com/mnielsen/neural-networks-and-deep-learning/blob/d15df08a69ed33ae16a2fff874f83b57a956172c/data/mnist.pkl.gz?raw=true'\n",
        "path_data = Path('data')\n",
        "path_data.mkdir(exist_ok=True )\n",
        "path_gz=path_data/'mnist.pkl.gz'\n",
        "path_gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dWUrQuMfniy3",
        "outputId": "5eb0c43b-4f88-4911-c440-a104374698f7"
      },
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PosixPath('data/mnist.pkl.gz')"
            ]
          },
          "metadata": {},
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from urllib.request import urlretrieve\n",
        "\n",
        "if not path_gz.exists(): urlretrieve(MNIST_URL, path_gz)"
      ],
      "metadata": {
        "id": "8Tg9Z2NKni06"
      },
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "\n",
        "mpl.rcParams['image.cmap'] = 'gray'\n",
        "torch.set_printoptions(precision=2, linewidth=125, sci_mode=False)\n",
        "np.set_printoptions(precision=2, linewidth=125)\n"
      ],
      "metadata": {
        "id": "y-R1O60Cni3P"
      },
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQ17fE1hni48",
        "outputId": "3ecf24f9-9191-49b4-b5c3-00e5fa5ffe31"
      },
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 16656\n",
            "-rw-r--r-- 1 root root 17051982 Jan 20 14:02 mnist.pkl.gz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with gzip.open(path_gz, 'rb') as f:   #read as binary as opposed to text\n",
        "   ((x_train,y_train), (x_valid,y_valid), _) = pickle.load(f, encoding='latin-1') #destructuring\n",
        "x_train, y_train, x_valid, y_valid = map(tensor, [x_train, y_train, x_valid, y_valid])"
      ],
      "metadata": {
        "id": "L5cfYFRwni6m"
      },
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W_TY16NRni8g"
      },
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n,m = x_train.shape\n",
        "c = y_train.max()+1\n",
        "nh = 50\n"
      ],
      "metadata": {
        "id": "-4wkKeZ7ni-G"
      },
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, n_in, nh, n_out):\n",
        "        super().__init__()\n",
        "        self.layers = [nn.Linear(n_in,nh), nn.ReLU(), nn.Linear(nh,n_out)]\n",
        "\n",
        "    def __call__(self, x):\n",
        "        for l in self.layers: x = l(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "ATdy9A7kni_1"
      },
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model(m, nh, 10)\n",
        "pred = model(x_train)\n",
        "pred.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4e2xfiynjCG",
        "outputId": "b7e92c87-cfb6-4586-c518-2c2f11518d0c"
      },
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([50000, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 168
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### CE loss"
      ],
      "metadata": {
        "id": "jyJTU38InjEc"
      },
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def log_softmax(x):\n",
        "  print(x.shape)\n",
        "  return (x.exp()/x.exp().sum(-1, keepdim=True)).shape\n",
        "log_softmax(pred)"
      ],
      "metadata": {
        "id": "8-nY1xrTnjG8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a127865-b668-41b0-96a6-2d78cb920f8a"
      },
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([50000, 10])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([50000, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 170
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def log_softmax(x):\n",
        "  # print(x.shape)\n",
        "  return (x.exp()/x.exp().sum(-1, keepdim=True)).log()\n",
        "log_softmax(pred)"
      ],
      "metadata": {
        "id": "nTI-2__pnjI9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92f6a58c-3b5e-48a3-fed8-7da25832c16d"
      },
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-2.36, -2.28, -2.09,  ..., -2.43, -2.47, -2.11],\n",
              "        [-2.37, -2.25, -2.09,  ..., -2.46, -2.43, -2.11],\n",
              "        [-2.34, -2.31, -2.14,  ..., -2.44, -2.48, -2.14],\n",
              "        ...,\n",
              "        [-2.26, -2.25, -2.13,  ..., -2.36, -2.53, -2.17],\n",
              "        [-2.39, -2.30, -2.18,  ..., -2.38, -2.42, -2.11],\n",
              "        [-2.40, -2.25, -2.14,  ..., -2.38, -2.45, -2.23]], grad_fn=<LogBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 171
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred.exp().shape , pred.exp().sum(-1)[:,None].shape"
      ],
      "metadata": {
        "id": "uEU_eMgOnjLT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d35fb47b-39e2-4d2a-c038-37fb934cd89f"
      },
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([50000, 10]), torch.Size([50000, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 172
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred.shape"
      ],
      "metadata": {
        "id": "h1sobHmEnjNV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2645364-2cdb-4c1d-812c-c33aa5e988c9"
      },
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([50000, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 173
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "we'll try to use log rules to simply softmax funcction\n",
        "\n",
        "`e^x and log x are opposite`"
      ],
      "metadata": {
        "id": "TLbz6V4BgpkD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def log_softmax(x):\n",
        "  return x - x.exp().sum(-1, keepdim=True).log()"
      ],
      "metadata": {
        "id": "saKpYskknjPN"
      },
      "execution_count": 174,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def logsumexp(x):\n",
        "  m = x.max(-1)[0]  # max value of `x`\n",
        "  return m + (x-m[:,None]).exp().sum(-1).log()  #logsumexp trick"
      ],
      "metadata": {
        "id": "sAK7z424njRn"
      },
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# in pytorch\n",
        "\n",
        "def log_softmax(x):\n",
        "  return x - x.logsumexp(-1, keepdim=True)"
      ],
      "metadata": {
        "id": "1WeVG0MNnjUq"
      },
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_close( logsumexp(pred), pred.logsumexp(-1))\n",
        "sm_pred = log_softmax(pred)\n",
        "sm_pred"
      ],
      "metadata": {
        "id": "W_I2zjpAnjXQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "875fb8c5-9e08-4f20-e13e-e41b0a0ff173"
      },
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-2.36, -2.28, -2.09,  ..., -2.43, -2.47, -2.11],\n",
              "        [-2.37, -2.25, -2.09,  ..., -2.46, -2.43, -2.11],\n",
              "        [-2.34, -2.31, -2.14,  ..., -2.44, -2.48, -2.14],\n",
              "        ...,\n",
              "        [-2.26, -2.25, -2.13,  ..., -2.36, -2.53, -2.17],\n",
              "        [-2.39, -2.30, -2.18,  ..., -2.38, -2.42, -2.11],\n",
              "        [-2.40, -2.25, -2.14,  ..., -2.38, -2.45, -2.23]], grad_fn=<SubBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 177
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The cross entropy loss for some target\n",
        " and some prediction  p(x) is given by:\n",
        "      - sum( x . log(p(x)))\n",
        "\n",
        "  But since our xs are 1-hot encoded (actually, they're just the integer indices), this can be rewritten as -log(pi) where i is the index of the desired target.\n",
        "\n",
        "This can be done using numpy-style integer array indexing. Note that PyTorch supports all the tricks in the advanced indexing methods discussed in that link."
      ],
      "metadata": {
        "id": "fET2pqYnkHwJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train[:3]  # actual values of y_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTBjjbCMjSDe",
        "outputId": "b0b60dd7-197b-4e2c-ca1f-cdb473a9aa5e"
      },
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([5, 0, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 178
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# now in our softmaax prediction `sm_pred`, we want to get 5th prediction of 0, 0th of 1, and 4th of 2\n",
        "\n",
        "sm_pred[0,5], sm_pred[1,0], sm_pred[2,4]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6d78JWNjSF4",
        "outputId": "efd7061d-a010-463f-ce4a-f6de22f7dcd7"
      },
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(-2.40, grad_fn=<SelectBackward0>),\n",
              " tensor(-2.37, grad_fn=<SelectBackward0>),\n",
              " tensor(-2.14, grad_fn=<SelectBackward0>))"
            ]
          },
          "metadata": {},
          "execution_count": 179
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sm_pred.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y1wUYT5DD7_l",
        "outputId": "74048686-b68a-4299-d4b9-5bb1f1d30db8"
      },
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([50000, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 180
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sm_pred[[0,1,2], y_train[:3]]     # [rows, cols]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LfE6014YjSHY",
        "outputId": "799e9a55-e31f-4daf-eddc-bcc9c5013249"
      },
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-2.40, -2.37, -2.14], grad_fn=<IndexBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 181
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sm_pred[range(y_train.shape[0])]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XlalSCABC8sq",
        "outputId": "b80083be-b979-4f18-847b-53ca23412a84"
      },
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-2.36, -2.28, -2.09,  ..., -2.43, -2.47, -2.11],\n",
              "        [-2.37, -2.25, -2.09,  ..., -2.46, -2.43, -2.11],\n",
              "        [-2.34, -2.31, -2.14,  ..., -2.44, -2.48, -2.14],\n",
              "        ...,\n",
              "        [-2.26, -2.25, -2.13,  ..., -2.36, -2.53, -2.17],\n",
              "        [-2.39, -2.30, -2.18,  ..., -2.38, -2.42, -2.11],\n",
              "        [-2.40, -2.25, -2.14,  ..., -2.38, -2.45, -2.23]], grad_fn=<IndexBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 182
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def nll(input, target): # this will cross entropy loss   # negative non-likelihood loss\n",
        "  return -input[range(target.shape[0]), target].mean()"
      ],
      "metadata": {
        "id": "W0ZnfBUBBAH8"
      },
      "execution_count": 183,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Pon5kkkpF5Aj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss = nll(sm_pred, y_train)\n",
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-lLmSkZZBAJ0",
        "outputId": "edc84bad-d2e9-4116-ff99-0d7952bc1686"
      },
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.30, grad_fn=<NegBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 184
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Then use PyTorch's implementation.\n",
        "test_close(F.nll_loss(F.log_softmax(pred, -1), y_train), loss, 1e-3)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qX3HBWS9BAL9"
      },
      "execution_count": 185,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# In PyTorch, F.log_softmax and F.nll_loss are combined in one optimized function, F.cross_entropy.\n",
        "test_close(F.cross_entropy(pred, y_train), loss, 1e-3)\n"
      ],
      "metadata": {
        "id": "wU6E_D6jBAOl"
      },
      "execution_count": 186,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dHLTJNjcjSJK"
      },
      "execution_count": 186,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6CgF_RGnjSL-"
      },
      "execution_count": 186,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# basic training loop\n",
        "\n",
        "Basic training loop\n",
        "Basically the training loop repeats over the following steps:\n",
        "\n",
        " * get the output of the model on a batch of inputs\n",
        " * compare the output to the labels we have and compute a loss\n",
        " * calculate the gradients of the loss with respect to every parameter of the model\n",
        " * update said parameters with those gradients to make them a little bit better"
      ],
      "metadata": {
        "id": "FA2j3Gv5F6mO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_func = F.cross_entropy"
      ],
      "metadata": {
        "id": "482EP6mgF9bT"
      },
      "execution_count": 187,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bs = 50  # batch size\n",
        "xb = x_train[0:bs]  # a mini batch from x\n",
        "preds = model(xb)\n",
        "\n",
        "preds[0], preds.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebpHPoCYF95s",
        "outputId": "d790e685-06f8-42fc-dbc3-a849210f67d9"
      },
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([-0.05,  0.03,  0.22,  0.02,  0.00, -0.09, -0.04, -0.12, -0.15,  0.20], grad_fn=<SelectBackward0>),\n",
              " torch.Size([50, 10]))"
            ]
          },
          "metadata": {},
          "execution_count": 188
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "yb = y_train[0:bs]\n",
        "yb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JS0UuditF970",
        "outputId": "49c76efe-f38f-4fa5-d428-fda8bf27ca06"
      },
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([5, 0, 4, 1, 9, 2, 1, 3, 1, 4, 3, 5, 3, 6, 1, 7, 2, 8, 6, 9, 4, 0, 9, 1, 1, 2, 4, 3, 2, 7, 3, 8, 6, 9, 0, 5, 6, 0, 7,\n",
              "        6, 1, 8, 7, 9, 3, 9, 8, 5, 9, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 189
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_func(preds, yb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AdqBuZ52F99e",
        "outputId": "29dc602a-10f3-4282-ffa0-fd6a47136f10"
      },
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.28, grad_fn=<NllLossBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 190
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds.argmax(dim=1) # for each rows in preds , find highest number"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8wQlEPfF9-2",
        "outputId": "66de757d-12b3-416a-f4ba-f8a106120768"
      },
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2, 2, 4, 2, 2, 9, 2, 2, 1, 9, 9, 9, 2, 2, 1, 2, 2, 2, 9, 9, 2, 2, 9, 2, 2, 2, 2, 2, 2, 1, 9, 1, 2, 2, 2, 9, 2, 9, 2,\n",
              "        9, 9, 2, 9, 2, 9, 2, 2, 2, 2, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 191
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(out, yb):\n",
        "  return (out.argmax(dim = 1) == yb).float().mean()"
      ],
      "metadata": {
        "id": "zqWDJEHAF-An"
      },
      "execution_count": 192,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy(preds, yb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lj2mupU0F-Cd",
        "outputId": "c3b0534b-f96c-491b-eee7-7897c37ac350"
      },
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.16)"
            ]
          },
          "metadata": {},
          "execution_count": 193
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.5\n",
        "epochs = 3"
      ],
      "metadata": {
        "id": "s3LsXd7DF-FI"
      },
      "execution_count": 194,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def report(loss, preds, yb):\n",
        "  print(f\"{loss:.2f}, {accuracy(preds,yb):.2f}\")"
      ],
      "metadata": {
        "id": "XwMP9mc0ZBx5"
      },
      "execution_count": 195,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xb,yb = x_train[:bs],y_train[:bs]\n",
        "preds = model(xb)\n",
        "report(loss_func(preds, yb), preds, yb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RgHpDCmiZB0b",
        "outputId": "bff96420-6e20-4518-beb7-2ca00365b5e2"
      },
      "execution_count": 196,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.28, 0.16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "  for i in range(0, n, bs):\n",
        "    s = slice(i, min(n, i+bs))\n",
        "    xb, yb = x_train[s], y_train[s]\n",
        "    preds = model(xb)\n",
        "    loss = loss_func(preds, yb)\n",
        "    loss.backward()\n",
        "\n",
        "    with torch.no_grad():\n",
        "      for l in model.layers:\n",
        "        if( hasattr( l , 'weight')):\n",
        "          l.weight -= l.weight.grad * lr\n",
        "          l.bias -= l.bias.grad * lr\n",
        "\n",
        "          l.weight.grad.zero_()\n",
        "          l.bias.grad.zero_()\n",
        "\n",
        "  report(loss, preds, yb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4b_3-z6ZB2Q",
        "outputId": "077519d7-30cd-4710-9721-5c92f2e722e7"
      },
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.08, 0.96\n",
            "0.05, 0.98\n",
            "0.07, 0.96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using parameters and optim\n"
      ],
      "metadata": {
        "id": "LvjRvSOMsmUc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## parameters"
      ],
      "metadata": {
        "id": "9um3Xn-yspoS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m1 = nn.Module()\n",
        "m1, list(m1.parameters())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mp9sRhMxZB4k",
        "outputId": "bbfc3e91-9838-4e40-8d03-2755af9447e8"
      },
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Module(), [])"
            ]
          },
          "metadata": {},
          "execution_count": 198
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m1.foo = nn.Linear(3,4)  #  the number of neurons in a linear layer is determined by the number of output features.\n",
        "m1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2e8gw1yQZB6s",
        "outputId": "56414432-4984-4806-c3f2-68277c0133a9"
      },
      "execution_count": 199,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Module(\n",
              "  (foo): Linear(in_features=3, out_features=4, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 199
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(m1.named_children())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_LUelpKuZB9J",
        "outputId": "25d96f6f-df84-4809-f50b-f3fb277f5a3c"
      },
      "execution_count": 200,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('foo', Linear(in_features=3, out_features=4, bias=True))]"
            ]
          },
          "metadata": {},
          "execution_count": 200
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m1.named_children()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FcnwVkdeZB_T",
        "outputId": "22819152-c91d-4e6d-d0ca-d31fb15ea40d"
      },
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<generator object Module.named_children at 0x7b62d43231b0>"
            ]
          },
          "metadata": {},
          "execution_count": 201
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(m1.parameters())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MzVAVIo3ZCBn",
        "outputId": "83c72375-bcaa-4843-c82b-385d56799c99"
      },
      "execution_count": 202,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([[-0.24, -0.11,  0.46],\n",
              "         [-0.17, -0.46, -0.07],\n",
              "         [-0.29,  0.31,  0.08],\n",
              "         [-0.24,  0.13, -0.17]], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([ 0.01,  0.51, -0.11, -0.47], requires_grad=True)]"
            ]
          },
          "metadata": {},
          "execution_count": 202
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# multi layer perceptron\n",
        "\n",
        "class MLP(nn.Module):\n",
        "  def __init__(self, n_in, nh, n_out):\n",
        "    super().__init__()\n",
        "    self.l1 = nn.Linear(n_in,nh )\n",
        "    self.l2 = nn.Linear(nh, n_out)\n",
        "    self.relu = nn.ReLU()\n",
        "\n",
        "\n",
        "  def __call__(self, x):\n",
        "    return self.l2(self.relu(self.l1(x)))"
      ],
      "metadata": {
        "id": "UnADJPssZCDt"
      },
      "execution_count": 203,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MLP(m, nh, 10)\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OVLbFwYFHxGt",
        "outputId": "f4ceea12-e258-4c0e-aa1d-9e5555cb2b06"
      },
      "execution_count": 204,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLP(\n",
              "  (l1): Linear(in_features=784, out_features=50, bias=True)\n",
              "  (l2): Linear(in_features=50, out_features=10, bias=True)\n",
              "  (relu): ReLU()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 204
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.l1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ol0NhBMcHxJM",
        "outputId": "d6b9b4f9-f81f-42f1-ff31-f6b7fa93713c"
      },
      "execution_count": 205,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=784, out_features=50, bias=True)"
            ]
          },
          "metadata": {},
          "execution_count": 205
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for name, l in model.named_children():\n",
        "  print(f\"{name}: {l}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29WWa9-xHxKz",
        "outputId": "6f5817d8-19df-4a61-b6d2-5bf4094bb930"
      },
      "execution_count": 206,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "l1: Linear(in_features=784, out_features=50, bias=True)\n",
            "l2: Linear(in_features=50, out_features=10, bias=True)\n",
            "relu: ReLU()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for p in model.parameters():   # parameters are `weights` + `bias`\n",
        "  print(p.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24nN-2UmHxMb",
        "outputId": "6dd740ce-7c72-4479-f735-4abf7327d6d5"
      },
      "execution_count": 207,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([50, 784])\n",
            "torch.Size([50])\n",
            "torch.Size([10, 50])\n",
            "torch.Size([10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[l for l in model.children()]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMEkqHmnTCa1",
        "outputId": "6f688d79-bc53-4e17-91f1-46d3438b050f"
      },
      "execution_count": 208,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Linear(in_features=784, out_features=50, bias=True),\n",
              " Linear(in_features=50, out_features=10, bias=True),\n",
              " ReLU()]"
            ]
          },
          "metadata": {},
          "execution_count": 208
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "torch.no_grad() is used to perform parameter updates without tracking gradients during this specific block of code.\n",
        "This is a common practice during the training loop when you have parts that involve updating the model parameters but don't need to be included\n",
        "in the gradient computation.\n",
        "\n",
        "\"\"\"\n",
        "def fit():\n",
        "  for epoch in range(epochs):\n",
        "    for i in range(0, n, bs):\n",
        "      s = slice(i , min(n, i+bs))\n",
        "      xb, yb = x_train[s], y_train[s]\n",
        "      preds = model(xb)\n",
        "\n",
        "      loss = loss_func(preds, yb)\n",
        "      loss.backward()  # it just computes gradients and stores gradients in `.grad`\n",
        "      with torch.no_grad():\n",
        "        for p in model.parameters():\n",
        "          p-= p.grad * lr   # manually updating parameters\n",
        "        model.zero_grad()  # to zero all gradients\n",
        "    report(loss, preds, yb)\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    but how does it know what paarameters and layers are automatically? it used a trick called __setattr__\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "fit()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZdLnbUyRHxPd",
        "outputId": "8ce2703f-c9a2-4b1c-ec42-abf141bf7c64"
      },
      "execution_count": 209,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.12, 0.96\n",
            "0.11, 0.98\n",
            "0.09, 0.96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Behind the scenes, PyTorch overrides the __setattr__ function in nn.Module so that the submodules you define are properly registered as parameters of the model.\n",
        "\n"
      ],
      "metadata": {
        "id": "pWTBM3IbO9Qu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#     but how does it know what paarameters and layers are automatically? it used a trick called __setattr__\n",
        "\n",
        "class MyModule:     # its by defult class MyModule(object)\n",
        "  def __init__(self, n_in, nh, n_out):\n",
        "    self._modules = {}\n",
        "    self.l1 = nn.Linear(n_in, nh)\n",
        "    self.l2 = nn.Linear(nh, n_out)\n",
        "\n",
        "\n",
        "  def __setattr__(self,k,v):\n",
        "        if not k.startswith(\"_\"): self._modules[k] = v  # to make sure its private  # it adds that attr in modules directory\n",
        "        super().__setattr__(k,v)\n",
        "\n",
        "        # every attibute you set like     self.l1 = nn.Linear(n_in, nh) , it\n",
        "\n",
        "  def __repr__(self): return f'{self._modules}'   # how it represents modules dic\n",
        "\n",
        "  def parameters(self):\n",
        "      for l in self._modules.values():   # go through each of modules.  value of modules is actual layers\n",
        "        yield from l.parameters()"
      ],
      "metadata": {
        "id": "jCk43FbqZCGe"
      },
      "execution_count": 210,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mdl = MyModule(m,nh,10)\n",
        "mdl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fT_mcq5SO-1J",
        "outputId": "7cec2302-2035-4058-b1a9-5519cc0ecbc9"
      },
      "execution_count": 211,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'l1': Linear(in_features=784, out_features=50, bias=True), 'l2': Linear(in_features=50, out_features=10, bias=True)}"
            ]
          },
          "metadata": {},
          "execution_count": 211
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mdl._modules"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8iJ8N7rHO-3u",
        "outputId": "7ef4a179-fac6-463c-fe84-6258fb895b09"
      },
      "execution_count": 212,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'l1': Linear(in_features=784, out_features=50, bias=True),\n",
              " 'l2': Linear(in_features=50, out_features=10, bias=True)}"
            ]
          },
          "metadata": {},
          "execution_count": 212
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for p in mdl.parameters(): print(p.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zq8-5RulO-6A",
        "outputId": "77ada01a-ce62-4df6-af3c-05247bca841a"
      },
      "execution_count": 213,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([50, 784])\n",
            "torch.Size([50])\n",
            "torch.Size([10, 50])\n",
            "torch.Size([10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def numbers_to_10():\n",
        "    for i in range(1, 11):\n",
        "        yield i\n",
        "\n",
        "def numbers_to_20():\n",
        "    yield from numbers_to_10()  # Yield values from another generator()..   if we dont use yield, values would be skipped\n",
        "    for i in range(11, 21):\n",
        "        yield i\n",
        "\n",
        "# for num in numbers_to_20():\n",
        "#     print(num)  # Outputs numbers 1 to 20\n",
        "\n",
        "list(numbers_to_20())"
      ],
      "metadata": {
        "id": "VkJ22jh1O-8X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91878eaf-aaf5-4cd2-dd66-f9e6f2531ec0"
      },
      "execution_count": 214,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]"
            ]
          },
          "metadata": {},
          "execution_count": 214
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(numbers_to_10())"
      ],
      "metadata": {
        "id": "Dr8TYpQ_O--m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54531cd3-bf0b-468f-803f-b98ec5be7d6a"
      },
      "execution_count": 215,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]"
            ]
          },
          "metadata": {},
          "execution_count": 215
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "numbers_to_10()"
      ],
      "metadata": {
        "id": "BTLsxBHwO_Aw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d7913c6-5e11-4de4-d9ca-9c479d5e431c"
      },
      "execution_count": 216,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<generator object numbers_to_10 at 0x7b62d4064a50>"
            ]
          },
          "metadata": {},
          "execution_count": 216
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2RNkeLywO_DK"
      },
      "execution_count": 216,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Registering modules"
      ],
      "metadata": {
        "id": "9uWNpUYHgQ9g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from functools import reduce"
      ],
      "metadata": {
        "id": "dCoZ7JWxO_Fd"
      },
      "execution_count": 217,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can use the original layers approach, but we have to register the modules.\n",
        "\n"
      ],
      "metadata": {
        "id": "Yfi3knfygflh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "layers = [  nn.Linear(m,nh),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(nh, 10)]\n",
        "layers"
      ],
      "metadata": {
        "id": "DCYYdL5nO_H9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "178a410f-1389-4e60-cd9b-ae458b187904"
      },
      "execution_count": 218,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Linear(in_features=784, out_features=50, bias=True),\n",
              " ReLU(),\n",
              " Linear(in_features=50, out_features=10, bias=True)]"
            ]
          },
          "metadata": {},
          "execution_count": 218
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from functools import reduce\n"
      ],
      "metadata": {
        "id": "uX49F94Ir1tv"
      },
      "execution_count": 219,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(nn.Module):\n",
        "  def __init__(self, layers):\n",
        "    super().__init__()\n",
        "    self.layers = layers\n",
        "    for i,l in enumerate(self.layers):\n",
        "      self.add_module(f'layer_{i}', l)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return reduce(lambda val, layer: layer(val), self.layers, x)  # reduce(reduction_function, self.layers, x)\n",
        "\n",
        "\n",
        "\"\"\"result = reduce(reduction_function, self.layers, x)\n",
        "The reduce function is called with three arguments:\n",
        "\n",
        "reduction_function: The binary function to apply cumulatively.\n",
        "self.layers: The iterable (list of layers) to apply the function to.\n",
        "x: The initial value to start the accumulation.\n",
        "The reduce function iterates through the layers, applying the lambda function to the accumulated value (val) and the current layer, updating the accumulated\n",
        "value at each step. The final result is the output of the last layer applied to the initial input x.\"\"\""
      ],
      "metadata": {
        "id": "w3iG5vLEO_Kn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "outputId": "07602907-c2e3-420c-d7ae-110b29aeb02b"
      },
      "execution_count": 220,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'result = reduce(reduction_function, self.layers, x)\\nThe reduce function is called with three arguments:\\n\\nreduction_function: The binary function to apply cumulatively.\\nself.layers: The iterable (list of layers) to apply the function to.\\nx: The initial value to start the accumulation.\\nThe reduce function iterates through the layers, applying the lambda function to the accumulated value (val) and the current layer, updating the accumulated \\nvalue at each step. The final result is the output of the last layer applied to the initial input x.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 220
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model(layers)\n",
        "model"
      ],
      "metadata": {
        "id": "MYNxUo9IO_Nn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5cd8a1f-e0e7-4d21-fc80-44bdab620102"
      },
      "execution_count": 221,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model(\n",
              "  (layer_0): Linear(in_features=784, out_features=50, bias=True)\n",
              "  (layer_1): ReLU()\n",
              "  (layer_2): Linear(in_features=50, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 221
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s= [ 1,2,3]\n",
        "\n",
        "reduce( lambda x,y : x+y,s , 10)"
      ],
      "metadata": {
        "id": "IAspKFE0O_QM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2024ee39-0ffb-4b98-f8fd-599d77faf4d8"
      },
      "execution_count": 222,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16"
            ]
          },
          "metadata": {},
          "execution_count": 222
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model(xb).shape"
      ],
      "metadata": {
        "id": "NtJzEim4O_Ro",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1e51f05-2536-414c-ea21-052d2cc5b8da"
      },
      "execution_count": 223,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([50, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 223
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ShabzRwvO_Uv"
      },
      "execution_count": 223,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KQgrxXr5t1Gk"
      },
      "execution_count": 223,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# nn.ModuleList\n",
        "  nn.ModuleList does this for us"
      ],
      "metadata": {
        "id": "lKAFmtrGt1St"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SequentialModel(nn.Module):\n",
        "  def __init__(self, layers):\n",
        "    super().__init__()\n",
        "    self.layers = nn.ModuleList(layers)# replaces `self.layers = layers; for i,l in enumerate(self.layers): self.add_module(f'layer_{i}', l)\n",
        "\n",
        "  # def forward(self,x):\n",
        "  #   for l in self.layers:x = l(x);\n",
        "  #   return x\n",
        "\n",
        "  def forward(self,x):\n",
        "    return reduce( lambda v,l :l(v), self.layers, x )"
      ],
      "metadata": {
        "id": "X39pxz57t1gU"
      },
      "execution_count": 224,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SequentialModel(layers)\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-KzTg-Dt1iX",
        "outputId": "33b2d367-0d74-48c0-b712-44446316728d"
      },
      "execution_count": 225,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SequentialModel(\n",
              "  (layers): ModuleList(\n",
              "    (0): Linear(in_features=784, out_features=50, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=50, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 225
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fit()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKooCATet1kb",
        "outputId": "4cd0cae3-8586-44d5-fb40-f427c7c1013b"
      },
      "execution_count": 226,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.13, 0.92\n",
            "0.10, 0.96\n",
            "0.08, 0.96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sHMn8B7vt1mt"
      },
      "execution_count": 226,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = [1,2,3,4,5,6]\n",
        "list(filter(lambda x : x%2 != 0 , x))"
      ],
      "metadata": {
        "id": "2Vayrt3t0elh",
        "outputId": "dc93d8b7-90d5-4ec1-f45e-8664607ce82c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 227,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 3, 5]"
            ]
          },
          "metadata": {},
          "execution_count": 227
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w93afbOi0eoR"
      },
      "execution_count": 227,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# nn.Sequential\n",
        "nn.Sequential does same by default\n"
      ],
      "metadata": {
        "id": "YEUPxdZJx4P0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.Sequential(nn.Linear(m,nh), nn.ReLU(), nn.Linear(nh,10))\n",
        "model\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4ugDI75t1oY",
        "outputId": "d5efcccd-c93b-4158-e603-4d1bad2f7b8c"
      },
      "execution_count": 228,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Linear(in_features=784, out_features=50, bias=True)\n",
              "  (1): ReLU()\n",
              "  (2): Linear(in_features=50, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 228
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fit()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQGkZnTAt1qR",
        "outputId": "6a54945a-aefb-47cf-bc52-60f830a26f59"
      },
      "execution_count": 229,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.16, 0.96\n",
            "0.10, 0.96\n",
            "0.05, 0.98\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_func(model(xb), yb),      accuracy(model(xb), yb)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQKMx_Kpt1sR",
        "outputId": "b8fc68fb-657c-4a22-ef1f-eb0e36a70823"
      },
      "execution_count": 230,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.02, grad_fn=<NllLossBackward0>), tensor(1.))"
            ]
          },
          "metadata": {},
          "execution_count": 230
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X3xmFBi0t1uV"
      },
      "execution_count": 230,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# optim"
      ],
      "metadata": {
        "id": "uo-qg4s1KCll"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Optimizer:\n",
        "  def __init__(self, params, lr = 0.5):\n",
        "    self.params, self.lr = list(params), lr\n",
        "\n",
        "  def step(self):\n",
        "    with torch.no_grad():\n",
        "      for p in self.params:\n",
        "        p -= p.grad * self.lr\n",
        "\n",
        "  def zero_grad(self):\n",
        "    for p in self.params:\n",
        "      p.grad.data.zero_()\n"
      ],
      "metadata": {
        "id": "l3O760FUt1xO"
      },
      "execution_count": 231,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.Sequential(\n",
        "    nn.Linear(m,nh),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(nh, 10)\n",
        ")"
      ],
      "metadata": {
        "id": "aADh8sEkKBQI"
      },
      "execution_count": 232,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "opt = Optimizer(model.parameters())"
      ],
      "metadata": {
        "id": "tCfG2Y_OKBSb"
      },
      "execution_count": 233,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "  for i in range(0 , n, bs):\n",
        "    s = slice(i, min(i+bs , n))\n",
        "\n",
        "    xb,yb = x_train[s], y_train[s]\n",
        "    preds = model(xb)\n",
        "\n",
        "    loss = loss_func(preds, yb)\n",
        "    loss.backward()  # computes gradients\n",
        "\n",
        "    opt.step()\n",
        "    opt.zero_grad()\n",
        "  report(loss, preds, yb)"
      ],
      "metadata": {
        "id": "OXVi-ET0KBU6",
        "outputId": "91486a9e-4eff-452f-f6b7-c6172f720ad2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 234,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.10, 0.98\n",
            "0.06, 1.00\n",
            "0.03, 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyTorch already provides this exact functionality in optim.SGD (it also handles stuff like momentum, which we'll look at later)"
      ],
      "metadata": {
        "id": "HdiUZjE0NNGO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import optim"
      ],
      "metadata": {
        "id": "-o9WK1-HKBYI"
      },
      "execution_count": 235,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model():\n",
        "  model = nn.Sequential(\n",
        "      nn.Linear(m,nh),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(nh, 10)\n",
        "  )\n",
        "  return model, optim.SGD(model.parameters(), lr = lr)"
      ],
      "metadata": {
        "id": "NO9UwiXSKBaE"
      },
      "execution_count": 236,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model, opt = get_model()\n",
        "loss_func( model(xb), yb)"
      ],
      "metadata": {
        "id": "fSC_Kk75KBb3",
        "outputId": "ee1a54e0-77b7-4b4a-b1d8-110506c52dcb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 237,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.31, grad_fn=<NllLossBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 237
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "    for i in range(0, n, bs):\n",
        "        s = slice(i, min(n,i+bs))\n",
        "        xb,yb = x_train[s],y_train[s]\n",
        "        preds = model(xb)\n",
        "        loss = loss_func(preds, yb)\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        opt.zero_grad()\n",
        "    report(loss, preds, yb)\n",
        "\n"
      ],
      "metadata": {
        "id": "V5lBiumGKBdl",
        "outputId": "26de0b9c-ebdc-427c-9f26-23f32e0a434c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 238,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.15, 0.92\n",
            "0.11, 0.96\n",
            "0.07, 0.96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5T5uZC0TOAyZ"
      },
      "execution_count": 238,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset and DataLoader\n"
      ],
      "metadata": {
        "id": "cN5hWwD3OFC2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset\n",
        "  It's clunky to iterate through minibatches of x and y values separately:\n",
        "  \n",
        "  \n",
        "* `xb,yb = x_train[s],y_train[s]`\n",
        "  instead let's do both steps together\n",
        "  `xb, yb = train_ds[s]`\n"
      ],
      "metadata": {
        "id": "mNYO0F2DOgRi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Dataset:\n",
        "  def __init__( self,x,y):\n",
        "    self.x, self.y = s,y\n",
        "\n",
        "  def __len__(self): return len(self.x)\n",
        "\n",
        "  def __getitem__(self, i): return self.x[i], self.y[i]"
      ],
      "metadata": {
        "id": "OliMs2JLOBnW"
      },
      "execution_count": 239,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds, valid_ds = Dataset(x_train)"
      ],
      "metadata": {
        "id": "DD3ydnA2OBpn"
      },
      "execution_count": 238,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R5nIrLsNOBry"
      },
      "execution_count": 238,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vMQ-5PypOBuO"
      },
      "execution_count": 238,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6ZrP3w5EOBwI"
      },
      "execution_count": 238,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kJOhEyS8OByU"
      },
      "execution_count": 238,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ziMQCMRAOB0O"
      },
      "execution_count": 238,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UAiVTWQ7OB2x"
      },
      "execution_count": 238,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0ZrhgP3cOB5g"
      },
      "execution_count": 238,
      "outputs": []
    }
  ]
}